---
title: "FraudDetectionClassifier"
author: "Anugya"
date: "1/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r loadPackages}
library(ranger)
library(caret)
library(data.table)
```
```{r readData}
creditcard_data <- read.csv("creditcard.csv")
#The values v1 to v28 are the results of PCA dimension reductions to protect sensitive information like user identities.

dim(creditcard_data)

head(creditcard_data, 6)

tail(creditcard_data, 6)

table(creditcard_data$Class)

summary(creditcard_data$Amount)

names(creditcard_data)

var(creditcard_data$Amount)

sd(creditcard_data$Amount)
```

```{r}
#data manipulation
head(creditcard_data)
creditcard_data$Amount <- scale(creditcard_data$Amount)
NewData <- creditcard_data[, -c(1)]
head(NewData)

```

```{r}
#data modelling
library(caTools)
set.seed(123)
data_sample <- sample.split(NewData$Class, SplitRatio = 0.80)
train_data <- subset(NewData, data_sample == TRUE)
test_data <- subset(NewData, data_sample == FALSE)

dim(train_data)
dim(test_data)
```
```{r}
#Fitting logistic regression model
Logistic_Model <- glm(Class~., test_data, family = binomial())

summary(Logistic_Model)
```

```{r}
#Plot model
plot(Logistic_Model)

#Analyze performance using ROC Receiver Otimistic Characteristic
library(pROC)
lr.predict <- predict(Logistic_Model,train_data, probability = TRUE)
auc.gbm = roc(train_data$Class, lr.predict, plot = TRUE, col = "blue")

lr.test.predict <- predict(Logistic_Model, test_data, probability=TRUE)
auc.test.gbm = roc(test_data$Class, lr.test.predict, plot=TRUE, col='blue')

```

```{r} 
#Fitting a decision tree
library(rpart)
library(rpart.plot)
decision_tree_model <- rpart(Class ~ . , creditcard_data, method = 'class')
predicted_value <- predict(decision_tree_model, creditcard_data, type = 'class')
probability_value <- predict(decision_tree_model, creditcard_data, type = 'prob')
rpart.plot(decision_tree_model)
```

```{r}
#Artificial Neural Network
library(neuralnet)
ann_model = neuralnet(Class ~ ., train_data,linear.output=FALSE)
plot(ann_model)

pred_ann <- compute(ann_model, test_data)
result_ann <- pred_ann$net.result

result_ann <- ifelse(result_ann > 0.5, 1,0)

```

```{r}
#Gradient Boosting

library(gbm, quietly = TRUE)

#Get the time to train the gbm model
system.time(
  model_gbm <- gbm(Class ~ ., distribution = 'bernoulli',
                   data = rbind(train_data, test_data),
                   n.trees = 500,
                   interaction.depth = 3,
                   n.minobsinnode = 100,
                   shrinkage = 0.01,
                   bag.fraction = 0.5,
                   train.fraction = nrow(train_data) / (nrow(train_data) + nrow(test_data))
                   )
           )

#Determine best iteration based on test data
gbm.iter = gbm.perf(model_gbm, method = 'test')

relative.influence(model_gbm, n.trees = gbm.iter, sort. = TRUE)

#Plot the gbm model
plot(model_gbm)

#Plot and calculate AUC on test data
gbm_test <- predict(model_gbm, newdata = test_data, n.trees = gbm.iter)
gbm_auc = roc(test_data$Class, gbm_test, plot = TRUE, col="red")

print(gbm_auc)
```
